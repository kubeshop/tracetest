services:
  llm-ui:
    build: ./app
    command:
      - opentelemetry-instrument
      - streamlit
      - run
      - streamlit_app.py
      - --server.port=8501
      - --server.address=0.0.0.0
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - OTEL_SERVICE_NAME=quick-start-llm-ui
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://otel-collector:4317
      - OTEL_PYTHON_DISABLED_INSTRUMENTATIONS=aleph_alpha_client,chromadb,cohere,groq,haystack-ai,lancedb,llama-index,marqo,milvus,mistralai,pinecone_client,qdrant_client,replicate,together,google_cloud_aiplatform,ibm-watson-machine-learning,weaviate_client
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - 8501:8501
    depends_on:
      - otel-collector

  llm-api:
    build: ./app
    command:
      - opentelemetry-instrument
      - python
      - flask_app.py
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - OTEL_SERVICE_NAME=quick-start-llm-api
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://otel-collector:4317
      - OTEL_PYTHON_DISABLED_INSTRUMENTATIONS=aleph_alpha_client,chromadb,cohere,groq,haystack-ai,lancedb,llama-index,marqo,milvus,mistralai,pinecone_client,qdrant_client,replicate,together,google_cloud_aiplatform,ibm-watson-machine-learning,weaviate_client
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - 8800:8800
    depends_on:
      - otel-collector

  otel-collector:
    command:
      - --config
      - /otel-local-config.yaml
    depends_on:
      jaeger:
        condition: service_started
    image: otel/opentelemetry-collector:0.108.0
    ports:
      - 4317:4317
    volumes:
      - type: bind
        source: ./observability/otelcollector.config.yaml
        target: /otel-local-config.yaml

  jaeger:
    healthcheck:
      test:
        - CMD
        - wget
        - --spider
        - localhost:16686
      timeout: 3s
      interval: 1s
      retries: 60
    image: jaegertracing/all-in-one:latest
    restart: unless-stopped
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - 16686:16686
      - 16685:16685

  # Cloud-based Managed Tracetest
  tracetest-agent:
    image: kubeshop/tracetest-agent:latest
    command: ["-v"]
    environment:
      # Get the required information here: https://app.tracetest.io/retrieve-token
      - TRACETEST_API_KEY=${TRACETEST_API_KEY}
      - TRACETEST_ENVIRONMENT_ID=${TRACETEST_ENVIRONMENT_ID}
      - TRACETEST_MODE=verbose

