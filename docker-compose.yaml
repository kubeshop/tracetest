version: "3.2"
services:
  tracetest:
    container_name: tracetest
    image: kubeshop/tracetest
    build:
      context: .
      args:
        VERSION: dev
        TRACETEST_ENV: docker-compose
    volumes:
      - type: bind
        source: ./local-config/config.tests.yaml
        target: /app/config.yaml
    ports:
      - 8080:8080
    depends_on:
      postgres:
        condition: service_healthy
      jaeger:
        condition: service_healthy
      demo-api:
        condition: service_healthy
      demo-rpc:
        condition: service_healthy
      otel-collector:
        condition: service_started

  postgres:
    container_name: postgres
    image: postgres
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_USER:  postgres
    ports:
      - 5432:5432
    healthcheck:
      test: pg_isready -U "$$POSTGRES_USER" -d "$$POSTGRES_DB"
      interval: 1s
      timeout: 5s
      retries: 60

  otel-collector:
    image: otel/opentelemetry-collector:0.54.0
    ports:
      - "55679:55679"
      - "4317:4317"
      - "8888:8888"
    command:
      - "--config"
      - "/otel-local-config.yaml"
    volumes:
      - ./local-config/collector.config.yaml:/otel-local-config.yaml
    environment:
      - JAEGER_ENDPOINT=jaeger:14250
      - LIGHTSTEP_TOKEN=<PLACE-YOUR-TOKEN-HERE>
    depends_on:
      jaeger:
        condition: service_healthy


  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "6831:6831/udp"
      - "16686:16686"
      - "16685:16685"
    healthcheck:
      test: ["CMD", "wget", "--spider", "localhost:16686"]
      interval: 1s
      timeout: 3s
      retries: 60

  cache:
    image: redis:6
    ports:
      - 6379:6379
    healthcheck:
      test: ["CMD", "redis-cli","ping"]
      interval: 1s
      timeout: 3s
      retries: 60

  queue:
    image: rabbitmq:3.9
    ports:
      - 5672:5672
      - 15672:15672
    healthcheck:
      test: rabbitmq-diagnostics -q check_running
      interval: 1s
      timeout: 5s
      retries: 60

  demo-api:
    image: kubeshop/demo-pokemon-api:latest
    pull_policy: always
    environment:
      REDIS_URL: cache
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/postgres?schema=public
      RABBITMQ_HOST: queue
      POKE_API_BASE_URL: https://pokeapi.co/api/v2
      JAEGER_HOST: jaeger
      JAEGER_PORT: 6832
      NPM_RUN_COMMAND: api
    ports:
      - "8081:8081"
    healthcheck:
      test: ["CMD", "wget", "--spider", "localhost:8081"]
      interval: 1s
      timeout: 3s
      retries: 60
    depends_on:
      postgres:
        condition: service_healthy
      cache:
        condition: service_healthy
      queue:
        condition: service_healthy
      jaeger:
        condition: service_healthy

  demo-worker:
    image: kubeshop/demo-pokemon-api:latest
    pull_policy: always
    environment:
      REDIS_URL: cache
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/postgres?schema=public
      RABBITMQ_HOST: queue
      POKE_API_BASE_URL: https://pokeapi.co/api/v2
      JAEGER_HOST: jaeger
      JAEGER_PORT: 6832
      NPM_RUN_COMMAND: worker
    depends_on:
      postgres:
        condition: service_healthy
      cache:
        condition: service_healthy
      queue:
        condition: service_healthy
      jaeger:
        condition: service_healthy

  demo-rpc:
    image: kubeshop/demo-pokemon-api:latest
    pull_policy: always
    environment:
      REDIS_URL: cache
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/postgres?schema=public
      RABBITMQ_HOST: queue
      POKE_API_BASE_URL: https://pokeapi.co/api/v2
      JAEGER_HOST: jaeger
      JAEGER_PORT: 6832
      NPM_RUN_COMMAND: rpc
    ports:
      - 8082:8082
    healthcheck:
      test: ["CMD","lsof", "-i", "8082"]
      interval: 1s
      timeout: 3s
      retries: 60
    depends_on:
      postgres:
        condition: service_healthy
      cache:
        condition: service_healthy
      queue:
        condition: service_healthy
      jaeger:
        condition: service_healthy

  data-prepper:
    restart: unless-stopped
    container_name: data-prepper
    image: opensearchproject/data-prepper:latest
    volumes:
      - ./local-config/opensearch/opensearch-analytics.yaml:/usr/share/data-prepper/pipelines.yaml
      - ./local-config/opensearch/opensearch-data-prepper-config.yaml:/usr/share/data-prepper/data-prepper-config.yaml
    ports:
      - "21890:21890"
    depends_on:
      - "opensearch"

  opensearch:
    image: opensearchproject/opensearch:latest
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
    volumes:
      - ./local-config/opensearch/opensearch.yaml:/usr/share/opensearch/config/opensearch.yml
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536 # maximum number of open files for the OpenSearch user, set to at least 65536 on modern systems
        hard: 65536
    ports:
      - 9200:9200
      - 9600:9600 # required for Performance Analyzer

  dashboards:
    image: opensearchproject/opensearch-dashboards:latest
    container_name: opensearch-dashboards
    ports:
      - 5601:5601
    expose:
      - "5601"
    environment:
      OPENSEARCH_HOSTS: '["http://opensearch:9200"]'
      OPENSEARCH_USERNAME: admin
      OPENSEARCH_PASSWORD: admin
    depends_on:
      - opensearch
