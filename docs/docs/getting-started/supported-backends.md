# Supported Backends

Currently, Tracetest supports the following backend data stores:

- Jaeger
- Grafana Tempo
- OpenSearch
- SignalFX

Details of configuring Tracetest to access these is discussed in the [installation instructions](./installation/).

We will be adding new data stores over the next couple of months - [let us know](https://github.com/kubeshop/tracetest/issues/new/choose) the ones you would to see us add support for.

## Using Tracetest Without a Backend

Another option is to not use a backend and send all traces directly to Tracetest using your OpenTelemetry Collector. And, you don't have to change your existing pipelines to do so.

### Configuring Your Collector to Send Traces to Tracetest

> :warning: It is important to notice that this relies on the [tailsampling](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor) processor, which, at the moment, is only available in the [contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/) version of the collector.


#### Creating a New Pipeline for Your Traces

```yaml
# your collector configuration file

# If you already have receivers declared, you can just ignore
# this one and still use yours instead.
receivers:
  otlp:
    protocols:
      grpc:
      http:

processors:
  # you will need to add this processor in order to only send spans
  # generated by tests to your Tracetest instance.
  tail_sampling:
    decision_wait: 5s
    policies:
      - name: tracetest-spans
        type: trace_state
        trace_state: { key: tracetest, values: ["true"] }

exporters:

  # This is the exporter that will send traces to Tracetest
  otlp/1:
    endpoint: http://your-tracetest-instance.com:21321
    tls:
      insecure: true

  batch:

service:
  pipelines:
    # your probably already have a traces pipeline, you don't have to change it.
    # just add this one to your configuration. Just make sure to not have two
    # pipelines with the same name
    traces/1:
      receivers: [otlp] # your receiver
      processors: [tail_sampling, batch] # make sure to have the tail_sampling before your batch processor
      exporters: [otlp/1] # your exporter pointing to your tracetest instance
```

#### Configuring your Tracetest Instance

You also have to configure your Tracetest instance to make it aware that there's no tracing backend to pull traces from. Just change your configuration file to include this configuration:

```yaml
# your tracetest config YAML file

telemetry:
    dataStores:
        otlp:
            type: otlp

    # rest of your telemetry configuration

server:
  telemetry:
    dataStore: otlp

# rest of the configuration file
```
